model_config:
  size: n
  device: "cpu"
inference_size: [ 640, 640 ]
log_level: DEBUG
redis:
  host: redis
  port: 6379
  stream_ids:
    - video1